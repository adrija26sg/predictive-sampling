{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.425966</td>\n",
       "      <td>0.960523</td>\n",
       "      <td>1.141109</td>\n",
       "      <td>-0.168252</td>\n",
       "      <td>0.420987</td>\n",
       "      <td>-0.029728</td>\n",
       "      <td>0.476201</td>\n",
       "      <td>0.260314</td>\n",
       "      <td>-0.568671</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208254</td>\n",
       "      <td>-0.559825</td>\n",
       "      <td>-0.026398</td>\n",
       "      <td>-0.371427</td>\n",
       "      <td>-0.232794</td>\n",
       "      <td>0.105915</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>1.229658</td>\n",
       "      <td>0.141004</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>1.202613</td>\n",
       "      <td>0.191881</td>\n",
       "      <td>0.272708</td>\n",
       "      <td>-0.005159</td>\n",
       "      <td>0.081213</td>\n",
       "      <td>0.464960</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.167716</td>\n",
       "      <td>-0.270710</td>\n",
       "      <td>-0.154104</td>\n",
       "      <td>-0.780055</td>\n",
       "      <td>0.750137</td>\n",
       "      <td>-0.257237</td>\n",
       "      <td>0.034507</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>-0.644269</td>\n",
       "      <td>1.417964</td>\n",
       "      <td>1.074380</td>\n",
       "      <td>-0.492199</td>\n",
       "      <td>0.948934</td>\n",
       "      <td>0.428118</td>\n",
       "      <td>1.120631</td>\n",
       "      <td>-3.807864</td>\n",
       "      <td>0.615375</td>\n",
       "      <td>...</td>\n",
       "      <td>1.943465</td>\n",
       "      <td>-1.015455</td>\n",
       "      <td>0.057504</td>\n",
       "      <td>-0.649709</td>\n",
       "      <td>-0.415267</td>\n",
       "      <td>-0.051634</td>\n",
       "      <td>-1.206921</td>\n",
       "      <td>-1.085339</td>\n",
       "      <td>40.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>-0.894286</td>\n",
       "      <td>0.286157</td>\n",
       "      <td>-0.113192</td>\n",
       "      <td>-0.271526</td>\n",
       "      <td>2.669599</td>\n",
       "      <td>3.721818</td>\n",
       "      <td>0.370145</td>\n",
       "      <td>0.851084</td>\n",
       "      <td>-0.392048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.268092</td>\n",
       "      <td>-0.204233</td>\n",
       "      <td>1.011592</td>\n",
       "      <td>0.373205</td>\n",
       "      <td>-0.384157</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.142404</td>\n",
       "      <td>93.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>-0.338262</td>\n",
       "      <td>1.119593</td>\n",
       "      <td>1.044367</td>\n",
       "      <td>-0.222187</td>\n",
       "      <td>0.499361</td>\n",
       "      <td>-0.246761</td>\n",
       "      <td>0.651583</td>\n",
       "      <td>0.069539</td>\n",
       "      <td>-0.736727</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.246914</td>\n",
       "      <td>-0.633753</td>\n",
       "      <td>-0.120794</td>\n",
       "      <td>-0.385050</td>\n",
       "      <td>-0.069733</td>\n",
       "      <td>0.094199</td>\n",
       "      <td>0.246219</td>\n",
       "      <td>0.083076</td>\n",
       "      <td>3.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0     0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2     1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3     1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4     2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "5     2 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728  0.476201   \n",
       "6     4  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708 -0.005159   \n",
       "7     7 -0.644269  1.417964  1.074380 -0.492199  0.948934  0.428118  1.120631   \n",
       "8     7 -0.894286  0.286157 -0.113192 -0.271526  2.669599  3.721818  0.370145   \n",
       "9     9 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761  0.651583   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "5  0.260314 -0.568671  ... -0.208254 -0.559825 -0.026398 -0.371427 -0.232794   \n",
       "6  0.081213  0.464960  ... -0.167716 -0.270710 -0.154104 -0.780055  0.750137   \n",
       "7 -3.807864  0.615375  ...  1.943465 -1.015455  0.057504 -0.649709 -0.415267   \n",
       "8  0.851084 -0.392048  ... -0.073425 -0.268092 -0.204233  1.011592  0.373205   \n",
       "9  0.069539 -0.736727  ... -0.246914 -0.633753 -0.120794 -0.385050 -0.069733   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      1  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "5  0.105915  0.253844  0.081080    3.67      0  \n",
       "6 -0.257237  0.034507  0.005168    4.99      0  \n",
       "7 -0.051634 -1.206921 -1.085339   40.80      0  \n",
       "8 -0.384157  0.011747  0.142404   93.20      0  \n",
       "9  0.094199  0.246219  0.083076    3.68      0  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('C:\\\\Users\\\\adrij\\\\OneDrive\\\\Desktop\\\\SAMPLING\\\\Creditcard_data.csv')\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Preview:\n",
      "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0     0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "1     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
      "2     1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "3     1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
      "4     2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
      "\n",
      "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
      "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
      "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
      "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
      "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
      "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
      "\n",
      "        V26       V27       V28  Amount  Class  \n",
      "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
      "1  0.125895 -0.008983  0.014724    2.69      1  \n",
      "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
      "3 -0.221929  0.062723  0.061458  123.50      0  \n",
      "4  0.502292  0.219422  0.215153   69.99      0  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "\n",
      "Dataset Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 772 entries, 0 to 771\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Time    772 non-null    int64  \n",
      " 1   V1      772 non-null    float64\n",
      " 2   V2      772 non-null    float64\n",
      " 3   V3      772 non-null    float64\n",
      " 4   V4      772 non-null    float64\n",
      " 5   V5      772 non-null    float64\n",
      " 6   V6      772 non-null    float64\n",
      " 7   V7      772 non-null    float64\n",
      " 8   V8      772 non-null    float64\n",
      " 9   V9      772 non-null    float64\n",
      " 10  V10     772 non-null    float64\n",
      " 11  V11     772 non-null    float64\n",
      " 12  V12     772 non-null    float64\n",
      " 13  V13     772 non-null    float64\n",
      " 14  V14     772 non-null    float64\n",
      " 15  V15     772 non-null    float64\n",
      " 16  V16     772 non-null    float64\n",
      " 17  V17     772 non-null    float64\n",
      " 18  V18     772 non-null    float64\n",
      " 19  V19     772 non-null    float64\n",
      " 20  V20     772 non-null    float64\n",
      " 21  V21     772 non-null    float64\n",
      " 22  V22     772 non-null    float64\n",
      " 23  V23     772 non-null    float64\n",
      " 24  V24     772 non-null    float64\n",
      " 25  V25     772 non-null    float64\n",
      " 26  V26     772 non-null    float64\n",
      " 27  V27     772 non-null    float64\n",
      " 28  V28     772 non-null    float64\n",
      " 29  Amount  772 non-null    float64\n",
      " 30  Class   772 non-null    int64  \n",
      "dtypes: float64(29), int64(2)\n",
      "memory usage: 187.1 KB\n",
      "None\n",
      "\n",
      "Statistical Summary:\n",
      "             Time          V1          V2          V3          V4          V5  \\\n",
      "count  772.000000  772.000000  772.000000  772.000000  772.000000  772.000000   \n",
      "mean   283.005181   -0.176963    0.217169    0.875172    0.285628   -0.005029   \n",
      "std    171.834196    1.294724    1.173401    1.031878    1.258758    1.098143   \n",
      "min      0.000000   -6.093248  -12.114213   -5.694973   -4.657545   -6.631951   \n",
      "25%    126.500000   -0.896416   -0.174684    0.308677   -0.460058   -0.534567   \n",
      "50%    282.000000   -0.382618    0.285843    0.905435    0.395919   -0.116612   \n",
      "75%    432.000000    1.110739    0.885745    1.532969    1.117559    0.452818   \n",
      "max    581.000000    1.586093    5.267376    3.772857    4.075817    7.672544   \n",
      "\n",
      "               V6          V7          V8          V9  ...         V21  \\\n",
      "count  772.000000  772.000000  772.000000  772.000000  ...  772.000000   \n",
      "mean     0.159081    0.123329   -0.057547   -0.030384  ...    0.004888   \n",
      "std      1.225682    0.852075    0.830144    0.878183  ...    0.609335   \n",
      "min     -3.498447   -4.925568   -7.494658   -2.770089  ...   -4.134608   \n",
      "25%     -0.630717   -0.296289   -0.167880   -0.517068  ...   -0.213746   \n",
      "50%     -0.109581    0.116329    0.034755   -0.082270  ...   -0.075802   \n",
      "75%      0.482972    0.575390    0.252395    0.412261  ...    0.095149   \n",
      "max      5.122103    4.808426    2.134599    5.459274  ...    5.273420   \n",
      "\n",
      "              V22         V23         V24         V25         V26         V27  \\\n",
      "count  772.000000  772.000000  772.000000  772.000000  772.000000  772.000000   \n",
      "mean    -0.096995   -0.040344   -0.002501    0.114337    0.022782    0.023353   \n",
      "std      0.607228    0.358724    0.621507    0.429667    0.484227    0.300934   \n",
      "min     -2.776923   -3.553381   -1.867208   -1.389079   -1.243924   -2.377933   \n",
      "25%     -0.525289   -0.176915   -0.379766   -0.166227   -0.313631   -0.047868   \n",
      "50%     -0.076551   -0.048353    0.091886    0.143723   -0.026414    0.023199   \n",
      "75%      0.307438    0.070085    0.426339    0.425798    0.260408    0.112199   \n",
      "max      1.574750    3.150413    1.215279    1.136720    3.087444    2.490503   \n",
      "\n",
      "              V28       Amount       Class  \n",
      "count  772.000000   772.000000  772.000000  \n",
      "mean    -0.017045    68.668290    0.011658  \n",
      "std      0.278332   197.838269    0.107411  \n",
      "min     -2.735623     0.000000    0.000000  \n",
      "25%     -0.033083     5.987500    0.000000  \n",
      "50%      0.021034    16.665000    0.000000  \n",
      "75%      0.087023    55.527500    0.000000  \n",
      "max      1.575380  3828.040000    1.000000  \n",
      "\n",
      "[8 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Preview:\")\n",
    "print(data.head())\n",
    "\n",
    "print(\"\\nDataset Information:\")\n",
    "print(data.info())\n",
    "\n",
    "print(\"\\nStatistical Summary:\")\n",
    "print(data.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Distribution:\n",
      "Class\n",
      "0    763\n",
      "1      9\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "class_counts = data['Class'].value_counts()\n",
    "print(\"\\nClass Distribution:\")\n",
    "print(class_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values in Each Column:\n",
      "Time      0\n",
      "V1        0\n",
      "V2        0\n",
      "V3        0\n",
      "V4        0\n",
      "V5        0\n",
      "V6        0\n",
      "V7        0\n",
      "V8        0\n",
      "V9        0\n",
      "V10       0\n",
      "V11       0\n",
      "V12       0\n",
      "V13       0\n",
      "V14       0\n",
      "V15       0\n",
      "V16       0\n",
      "V17       0\n",
      "V18       0\n",
      "V19       0\n",
      "V20       0\n",
      "V21       0\n",
      "V22       0\n",
      "V23       0\n",
      "V24       0\n",
      "V25       0\n",
      "V26       0\n",
      "V27       0\n",
      "V28       0\n",
      "Amount    0\n",
      "Class     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values = data.isnull().sum()\n",
    "print(\"\\nMissing Values in Each Column:\")\n",
    "print(missing_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Legitimate Transactions: 763\n",
      "Number of Fraudulent Transactions: 9\n"
     ]
    }
   ],
   "source": [
    "legit_transactions = data[data['Class'] == 0]\n",
    "fraudulent_transactions = data[data['Class'] == 1]\n",
    "\n",
    "print(\"\\nNumber of Legitimate Transactions:\", legit_transactions.shape[0])\n",
    "print(\"Number of Fraudulent Transactions:\", fraudulent_transactions.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "class_counts.plot(kind='bar', color=['green', 'red'], title=\"Class Distribution\")\n",
    "plt.xlabel(\"Transaction Class (0: Legit, 1: Fraud)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Balanced Class Distribution:\n",
      "Class\n",
      "0    763\n",
      "1    763\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X = data.drop('Class', axis=1)\n",
    "y = data['Class']\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_balanced, y_balanced = smote.fit_resample(X, y)\n",
    "\n",
    "print(\"\\nBalanced Class Distribution:\")\n",
    "print(pd.Series(y_balanced).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Balanced Dataset Shape: (1526, 31)\n"
     ]
    }
   ],
   "source": [
    "balanced_data = pd.concat([pd.DataFrame(X_balanced), pd.DataFrame(y_balanced, columns=['Class'])], axis=1)\n",
    "\n",
    "print(\"\\nBalanced Dataset Shape:\", balanced_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Sizes: [305, 306, 306, 305, 305]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adrij\\AppData\\Local\\Temp\\ipykernel_19328\\2421784727.py:7: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  stratified_sample = balanced_data.groupby('Class').apply(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Random Sampling\n",
    "random_sample = balanced_data.sample(frac=0.2, random_state=42)\n",
    "\n",
    "# Stratified Sampling\n",
    "stratified_sample = balanced_data.groupby('Class').apply(\n",
    "    lambda group: group.sample(frac=0.2, random_state=42)\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Systematic Sampling\n",
    "step_size = len(balanced_data) // int(0.2 * len(balanced_data))\n",
    "systematic_sample = balanced_data.iloc[::step_size, :]\n",
    "\n",
    "# Cluster Sampling\n",
    "clusters = 5\n",
    "balanced_data['ClusterID'] = balanced_data.index % clusters\n",
    "selected_cluster = np.random.choice(range(clusters))\n",
    "cluster_sample = balanced_data[balanced_data['ClusterID'] == selected_cluster].drop('ClusterID', axis=1)\n",
    "\n",
    "# Bootstrap Sampling\n",
    "bootstrap_sample = balanced_data.sample(frac=0.2, replace=True, random_state=42)\n",
    "\n",
    "# Verify Sample Sizes\n",
    "samples = [random_sample, stratified_sample, systematic_sample, cluster_sample, bootstrap_sample]\n",
    "sample_sizes = [len(sample) for sample in samples]\n",
    "print(\"\\nSample Sizes:\", sample_sizes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "    \"SVM\": SVC(),\n",
    "    \"k-NN\": KNeighborsClassifier()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adrij\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adrij\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adrij\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adrij\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adrij\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Accuracy:\n",
      "            Logistic Regression  Decision Tree  Gradient Boosting       SVM  \\\n",
      "Random                 0.918033       0.901639           0.934426  0.721311   \n",
      "Stratified             0.951613       0.919355           0.967742  0.725806   \n",
      "Systematic             0.741935       0.887097           0.951613  0.677419   \n",
      "Cluster                0.836066       0.868852           0.885246  0.655738   \n",
      "Bootstrap              0.950820       0.967213           0.967213  0.639344   \n",
      "\n",
      "                k-NN  \n",
      "Random      0.655738  \n",
      "Stratified  0.741935  \n",
      "Systematic  0.725806  \n",
      "Cluster     0.704918  \n",
      "Bootstrap   0.754098  \n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    results[model_name] = []\n",
    "    \n",
    "    for i, sample in enumerate(samples):\n",
    "        X_sample = sample.drop('Class', axis=1)\n",
    "        y_sample = sample['Class']\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.2, random_state=42)\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        \n",
    "        results[model_name].append(accuracy)\n",
    "\n",
    "accuracy_table = pd.DataFrame(results, index=[\"Random\", \"Stratified\", \"Systematic\", \"Cluster\", \"Bootstrap\"])\n",
    "print(\"\\nModel Accuracy:\")\n",
    "print(accuracy_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_table.to_csv('Fraud_Detection_Results.csv', index_label='Sampling Method')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
