{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.425966</td>\n",
       "      <td>0.960523</td>\n",
       "      <td>1.141109</td>\n",
       "      <td>-0.168252</td>\n",
       "      <td>0.420987</td>\n",
       "      <td>-0.029728</td>\n",
       "      <td>0.476201</td>\n",
       "      <td>0.260314</td>\n",
       "      <td>-0.568671</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208254</td>\n",
       "      <td>-0.559825</td>\n",
       "      <td>-0.026398</td>\n",
       "      <td>-0.371427</td>\n",
       "      <td>-0.232794</td>\n",
       "      <td>0.105915</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>1.229658</td>\n",
       "      <td>0.141004</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>1.202613</td>\n",
       "      <td>0.191881</td>\n",
       "      <td>0.272708</td>\n",
       "      <td>-0.005159</td>\n",
       "      <td>0.081213</td>\n",
       "      <td>0.464960</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.167716</td>\n",
       "      <td>-0.270710</td>\n",
       "      <td>-0.154104</td>\n",
       "      <td>-0.780055</td>\n",
       "      <td>0.750137</td>\n",
       "      <td>-0.257237</td>\n",
       "      <td>0.034507</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>-0.644269</td>\n",
       "      <td>1.417964</td>\n",
       "      <td>1.074380</td>\n",
       "      <td>-0.492199</td>\n",
       "      <td>0.948934</td>\n",
       "      <td>0.428118</td>\n",
       "      <td>1.120631</td>\n",
       "      <td>-3.807864</td>\n",
       "      <td>0.615375</td>\n",
       "      <td>...</td>\n",
       "      <td>1.943465</td>\n",
       "      <td>-1.015455</td>\n",
       "      <td>0.057504</td>\n",
       "      <td>-0.649709</td>\n",
       "      <td>-0.415267</td>\n",
       "      <td>-0.051634</td>\n",
       "      <td>-1.206921</td>\n",
       "      <td>-1.085339</td>\n",
       "      <td>40.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>-0.894286</td>\n",
       "      <td>0.286157</td>\n",
       "      <td>-0.113192</td>\n",
       "      <td>-0.271526</td>\n",
       "      <td>2.669599</td>\n",
       "      <td>3.721818</td>\n",
       "      <td>0.370145</td>\n",
       "      <td>0.851084</td>\n",
       "      <td>-0.392048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.268092</td>\n",
       "      <td>-0.204233</td>\n",
       "      <td>1.011592</td>\n",
       "      <td>0.373205</td>\n",
       "      <td>-0.384157</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.142404</td>\n",
       "      <td>93.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>-0.338262</td>\n",
       "      <td>1.119593</td>\n",
       "      <td>1.044367</td>\n",
       "      <td>-0.222187</td>\n",
       "      <td>0.499361</td>\n",
       "      <td>-0.246761</td>\n",
       "      <td>0.651583</td>\n",
       "      <td>0.069539</td>\n",
       "      <td>-0.736727</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.246914</td>\n",
       "      <td>-0.633753</td>\n",
       "      <td>-0.120794</td>\n",
       "      <td>-0.385050</td>\n",
       "      <td>-0.069733</td>\n",
       "      <td>0.094199</td>\n",
       "      <td>0.246219</td>\n",
       "      <td>0.083076</td>\n",
       "      <td>3.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0     0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2     1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3     1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4     2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "5     2 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728  0.476201   \n",
       "6     4  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708 -0.005159   \n",
       "7     7 -0.644269  1.417964  1.074380 -0.492199  0.948934  0.428118  1.120631   \n",
       "8     7 -0.894286  0.286157 -0.113192 -0.271526  2.669599  3.721818  0.370145   \n",
       "9     9 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761  0.651583   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "5  0.260314 -0.568671  ... -0.208254 -0.559825 -0.026398 -0.371427 -0.232794   \n",
       "6  0.081213  0.464960  ... -0.167716 -0.270710 -0.154104 -0.780055  0.750137   \n",
       "7 -3.807864  0.615375  ...  1.943465 -1.015455  0.057504 -0.649709 -0.415267   \n",
       "8  0.851084 -0.392048  ... -0.073425 -0.268092 -0.204233  1.011592  0.373205   \n",
       "9  0.069539 -0.736727  ... -0.246914 -0.633753 -0.120794 -0.385050 -0.069733   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      1  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "5  0.105915  0.253844  0.081080    3.67      0  \n",
       "6 -0.257237  0.034507  0.005168    4.99      0  \n",
       "7 -0.051634 -1.206921 -1.085339   40.80      0  \n",
       "8 -0.384157  0.011747  0.142404   93.20      0  \n",
       "9  0.094199  0.246219  0.083076    3.68      0  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transaction_data = pd.read_csv('C:\\\\Users\\\\adrij\\\\OneDrive\\\\Desktop\\\\SAMPLING\\\\Creditcard_data.csv')\n",
    "\n",
    "transaction_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 772 entries, 0 to 771\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Time    772 non-null    int64  \n",
      " 1   V1      772 non-null    float64\n",
      " 2   V2      772 non-null    float64\n",
      " 3   V3      772 non-null    float64\n",
      " 4   V4      772 non-null    float64\n",
      " 5   V5      772 non-null    float64\n",
      " 6   V6      772 non-null    float64\n",
      " 7   V7      772 non-null    float64\n",
      " 8   V8      772 non-null    float64\n",
      " 9   V9      772 non-null    float64\n",
      " 10  V10     772 non-null    float64\n",
      " 11  V11     772 non-null    float64\n",
      " 12  V12     772 non-null    float64\n",
      " 13  V13     772 non-null    float64\n",
      " 14  V14     772 non-null    float64\n",
      " 15  V15     772 non-null    float64\n",
      " 16  V16     772 non-null    float64\n",
      " 17  V17     772 non-null    float64\n",
      " 18  V18     772 non-null    float64\n",
      " 19  V19     772 non-null    float64\n",
      " 20  V20     772 non-null    float64\n",
      " 21  V21     772 non-null    float64\n",
      " 22  V22     772 non-null    float64\n",
      " 23  V23     772 non-null    float64\n",
      " 24  V24     772 non-null    float64\n",
      " 25  V25     772 non-null    float64\n",
      " 26  V26     772 non-null    float64\n",
      " 27  V27     772 non-null    float64\n",
      " 28  V28     772 non-null    float64\n",
      " 29  Amount  772 non-null    float64\n",
      " 30  Class   772 non-null    int64  \n",
      "dtypes: float64(29), int64(2)\n",
      "memory usage: 187.1 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 772 entries, 0 to 771\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Time    772 non-null    int64  \n",
      " 1   V1      772 non-null    float64\n",
      " 2   V2      772 non-null    float64\n",
      " 3   V3      772 non-null    float64\n",
      " 4   V4      772 non-null    float64\n",
      " 5   V5      772 non-null    float64\n",
      " 6   V6      772 non-null    float64\n",
      " 7   V7      772 non-null    float64\n",
      " 8   V8      772 non-null    float64\n",
      " 9   V9      772 non-null    float64\n",
      " 10  V10     772 non-null    float64\n",
      " 11  V11     772 non-null    float64\n",
      " 12  V12     772 non-null    float64\n",
      " 13  V13     772 non-null    float64\n",
      " 14  V14     772 non-null    float64\n",
      " 15  V15     772 non-null    float64\n",
      " 16  V16     772 non-null    float64\n",
      " 17  V17     772 non-null    float64\n",
      " 18  V18     772 non-null    float64\n",
      " 19  V19     772 non-null    float64\n",
      " 20  V20     772 non-null    float64\n",
      " 21  V21     772 non-null    float64\n",
      " 22  V22     772 non-null    float64\n",
      " 23  V23     772 non-null    float64\n",
      " 24  V24     772 non-null    float64\n",
      " 25  V25     772 non-null    float64\n",
      " 26  V26     772 non-null    float64\n",
      " 27  V27     772 non-null    float64\n",
      " 28  V28     772 non-null    float64\n",
      " 29  Amount  772 non-null    float64\n",
      " 30  Class   772 non-null    int64  \n",
      "dtypes: float64(29), int64(2)\n",
      "memory usage: 187.1 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>283.005181</td>\n",
       "      <td>-0.176963</td>\n",
       "      <td>0.217169</td>\n",
       "      <td>0.875172</td>\n",
       "      <td>0.285628</td>\n",
       "      <td>-0.005029</td>\n",
       "      <td>0.159081</td>\n",
       "      <td>0.123329</td>\n",
       "      <td>-0.057547</td>\n",
       "      <td>-0.030384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004888</td>\n",
       "      <td>-0.096995</td>\n",
       "      <td>-0.040344</td>\n",
       "      <td>-0.002501</td>\n",
       "      <td>0.114337</td>\n",
       "      <td>0.022782</td>\n",
       "      <td>0.023353</td>\n",
       "      <td>-0.017045</td>\n",
       "      <td>68.668290</td>\n",
       "      <td>0.011658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>171.834196</td>\n",
       "      <td>1.294724</td>\n",
       "      <td>1.173401</td>\n",
       "      <td>1.031878</td>\n",
       "      <td>1.258758</td>\n",
       "      <td>1.098143</td>\n",
       "      <td>1.225682</td>\n",
       "      <td>0.852075</td>\n",
       "      <td>0.830144</td>\n",
       "      <td>0.878183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.609335</td>\n",
       "      <td>0.607228</td>\n",
       "      <td>0.358724</td>\n",
       "      <td>0.621507</td>\n",
       "      <td>0.429667</td>\n",
       "      <td>0.484227</td>\n",
       "      <td>0.300934</td>\n",
       "      <td>0.278332</td>\n",
       "      <td>197.838269</td>\n",
       "      <td>0.107411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-6.093248</td>\n",
       "      <td>-12.114213</td>\n",
       "      <td>-5.694973</td>\n",
       "      <td>-4.657545</td>\n",
       "      <td>-6.631951</td>\n",
       "      <td>-3.498447</td>\n",
       "      <td>-4.925568</td>\n",
       "      <td>-7.494658</td>\n",
       "      <td>-2.770089</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.134608</td>\n",
       "      <td>-2.776923</td>\n",
       "      <td>-3.553381</td>\n",
       "      <td>-1.867208</td>\n",
       "      <td>-1.389079</td>\n",
       "      <td>-1.243924</td>\n",
       "      <td>-2.377933</td>\n",
       "      <td>-2.735623</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>126.500000</td>\n",
       "      <td>-0.896416</td>\n",
       "      <td>-0.174684</td>\n",
       "      <td>0.308677</td>\n",
       "      <td>-0.460058</td>\n",
       "      <td>-0.534567</td>\n",
       "      <td>-0.630717</td>\n",
       "      <td>-0.296289</td>\n",
       "      <td>-0.167880</td>\n",
       "      <td>-0.517068</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.213746</td>\n",
       "      <td>-0.525289</td>\n",
       "      <td>-0.176915</td>\n",
       "      <td>-0.379766</td>\n",
       "      <td>-0.166227</td>\n",
       "      <td>-0.313631</td>\n",
       "      <td>-0.047868</td>\n",
       "      <td>-0.033083</td>\n",
       "      <td>5.987500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>282.000000</td>\n",
       "      <td>-0.382618</td>\n",
       "      <td>0.285843</td>\n",
       "      <td>0.905435</td>\n",
       "      <td>0.395919</td>\n",
       "      <td>-0.116612</td>\n",
       "      <td>-0.109581</td>\n",
       "      <td>0.116329</td>\n",
       "      <td>0.034755</td>\n",
       "      <td>-0.082270</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075802</td>\n",
       "      <td>-0.076551</td>\n",
       "      <td>-0.048353</td>\n",
       "      <td>0.091886</td>\n",
       "      <td>0.143723</td>\n",
       "      <td>-0.026414</td>\n",
       "      <td>0.023199</td>\n",
       "      <td>0.021034</td>\n",
       "      <td>16.665000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>432.000000</td>\n",
       "      <td>1.110739</td>\n",
       "      <td>0.885745</td>\n",
       "      <td>1.532969</td>\n",
       "      <td>1.117559</td>\n",
       "      <td>0.452818</td>\n",
       "      <td>0.482972</td>\n",
       "      <td>0.575390</td>\n",
       "      <td>0.252395</td>\n",
       "      <td>0.412261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095149</td>\n",
       "      <td>0.307438</td>\n",
       "      <td>0.070085</td>\n",
       "      <td>0.426339</td>\n",
       "      <td>0.425798</td>\n",
       "      <td>0.260408</td>\n",
       "      <td>0.112199</td>\n",
       "      <td>0.087023</td>\n",
       "      <td>55.527500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>581.000000</td>\n",
       "      <td>1.586093</td>\n",
       "      <td>5.267376</td>\n",
       "      <td>3.772857</td>\n",
       "      <td>4.075817</td>\n",
       "      <td>7.672544</td>\n",
       "      <td>5.122103</td>\n",
       "      <td>4.808426</td>\n",
       "      <td>2.134599</td>\n",
       "      <td>5.459274</td>\n",
       "      <td>...</td>\n",
       "      <td>5.273420</td>\n",
       "      <td>1.574750</td>\n",
       "      <td>3.150413</td>\n",
       "      <td>1.215279</td>\n",
       "      <td>1.136720</td>\n",
       "      <td>3.087444</td>\n",
       "      <td>2.490503</td>\n",
       "      <td>1.575380</td>\n",
       "      <td>3828.040000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Time          V1          V2          V3          V4          V5  \\\n",
       "count  772.000000  772.000000  772.000000  772.000000  772.000000  772.000000   \n",
       "mean   283.005181   -0.176963    0.217169    0.875172    0.285628   -0.005029   \n",
       "std    171.834196    1.294724    1.173401    1.031878    1.258758    1.098143   \n",
       "min      0.000000   -6.093248  -12.114213   -5.694973   -4.657545   -6.631951   \n",
       "25%    126.500000   -0.896416   -0.174684    0.308677   -0.460058   -0.534567   \n",
       "50%    282.000000   -0.382618    0.285843    0.905435    0.395919   -0.116612   \n",
       "75%    432.000000    1.110739    0.885745    1.532969    1.117559    0.452818   \n",
       "max    581.000000    1.586093    5.267376    3.772857    4.075817    7.672544   \n",
       "\n",
       "               V6          V7          V8          V9  ...         V21  \\\n",
       "count  772.000000  772.000000  772.000000  772.000000  ...  772.000000   \n",
       "mean     0.159081    0.123329   -0.057547   -0.030384  ...    0.004888   \n",
       "std      1.225682    0.852075    0.830144    0.878183  ...    0.609335   \n",
       "min     -3.498447   -4.925568   -7.494658   -2.770089  ...   -4.134608   \n",
       "25%     -0.630717   -0.296289   -0.167880   -0.517068  ...   -0.213746   \n",
       "50%     -0.109581    0.116329    0.034755   -0.082270  ...   -0.075802   \n",
       "75%      0.482972    0.575390    0.252395    0.412261  ...    0.095149   \n",
       "max      5.122103    4.808426    2.134599    5.459274  ...    5.273420   \n",
       "\n",
       "              V22         V23         V24         V25         V26         V27  \\\n",
       "count  772.000000  772.000000  772.000000  772.000000  772.000000  772.000000   \n",
       "mean    -0.096995   -0.040344   -0.002501    0.114337    0.022782    0.023353   \n",
       "std      0.607228    0.358724    0.621507    0.429667    0.484227    0.300934   \n",
       "min     -2.776923   -3.553381   -1.867208   -1.389079   -1.243924   -2.377933   \n",
       "25%     -0.525289   -0.176915   -0.379766   -0.166227   -0.313631   -0.047868   \n",
       "50%     -0.076551   -0.048353    0.091886    0.143723   -0.026414    0.023199   \n",
       "75%      0.307438    0.070085    0.426339    0.425798    0.260408    0.112199   \n",
       "max      1.574750    3.150413    1.215279    1.136720    3.087444    2.490503   \n",
       "\n",
       "              V28       Amount       Class  \n",
       "count  772.000000   772.000000  772.000000  \n",
       "mean    -0.017045    68.668290    0.011658  \n",
       "std      0.278332   197.838269    0.107411  \n",
       "min     -2.735623     0.000000    0.000000  \n",
       "25%     -0.033083     5.987500    0.000000  \n",
       "50%      0.021034    16.665000    0.000000  \n",
       "75%      0.087023    55.527500    0.000000  \n",
       "max      1.575380  3828.040000    1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transaction_data.head()\n",
    "transaction_data.info()\n",
    "transaction_data.describe()\n",
    "transaction_data.head() # Displays the first few rows of the dataset\n",
    "transaction_data.info() # Shows the structure and summary of the dataset\n",
    "transaction_data.describe()  #Provides statistical insights into numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction Types:\n",
      "Class\n",
      "0    763\n",
      "1      9\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "fraud_distribution = transaction_data[\"Class\"].value_counts()\n",
    "print(\"Transaction Types:\")\n",
    "print(fraud_distribution)# Analyzes the distribution of fraud vs. non-fraud transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Values Per Feature:\n",
      "Time      0\n",
      "V1        0\n",
      "V2        0\n",
      "V3        0\n",
      "V4        0\n",
      "V5        0\n",
      "V6        0\n",
      "V7        0\n",
      "V8        0\n",
      "V9        0\n",
      "V10       0\n",
      "V11       0\n",
      "V12       0\n",
      "V13       0\n",
      "V14       0\n",
      "V15       0\n",
      "V16       0\n",
      "V17       0\n",
      "V18       0\n",
      "V19       0\n",
      "V20       0\n",
      "V21       0\n",
      "V22       0\n",
      "V23       0\n",
      "V24       0\n",
      "V25       0\n",
      "V26       0\n",
      "V27       0\n",
      "V28       0\n",
      "Amount    0\n",
      "Class     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "null_count = transaction_data.isna().sum()\n",
    "print(\"Null Values Per Feature:\")\n",
    "print(null_count)#Identifies missing or null values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Legitimate Transactions: 763\n",
      "Number of Fraudulent Transactions: 9\n"
     ]
    }
   ],
   "source": [
    "legit_transactions = data[data['Class'] == 0]\n",
    "fraudulent_transactions = data[data['Class'] == 1]\n",
    "\n",
    "print(\"\\nNumber of Legitimate Transactions:\", legit_transactions.shape[0])\n",
    "print(\"Number of Fraudulent Transactions:\", fraudulent_transactions.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal transactions: (763, 31)\n",
      "Fraudulent transactions: (9, 31)\n"
     ]
    }
   ],
   "source": [
    "normal_trans = transaction_data[transaction_data['Class'] == 0]\n",
    "fraud_trans = transaction_data[transaction_data['Class'] == 1]\n",
    "print('Normal transactions:', normal_trans.shape)\n",
    "print('Fraudulent transactions:', fraud_trans.shape)# Separates the dataset into normal and fraudulent transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Class')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA00AAAHWCAYAAACrPWKFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAxF0lEQVR4nO3de7yVY/4//vfusHeldmedTxIqFSNMzJARyfmcwxDGaZTzx/mhYsYw44MZNAw+w6BBB2KMUxIGISVKFKNikCZ0UCn2vn5/9Gt9LTu3ym4v6fl8PNbj4b7va933e13XWlavfd/3tYpSSikAAABYrWqFLgAAAOCHTGgCAADIIDQBAABkEJoAAAAyCE0AAAAZhCYAAIAMQhMAAEAGoQkAACCD0AQAAJBBaALYyB133HHRvn37Qpfxo9S7d+/o3bt3lRyrqKgohg4dmlseOnRoFBUVxfz586vk+O3bt4/jjjuuSo4FUNWEJmCjUFRUtEaPp59+utClrhcffvhhDB06NKZMmVLoUiJiZZhYk/H4eggotOOOOy6vtrp168Zmm20Whx56aIwePTrKy8sr5TgvvPBCDB06NBYsWFAp+6tMP+TaANanGoUuAKAq3HXXXXnLd955Z4wdO7bC+s6dO1dlWVXmww8/jMsuuyzat28f22yzTd62W2+9tdL+wb+mLrnkkjjxxBNzyxMnTozrr78+Lr744rwx6N69e5XW9V1KSkritttui4iIZcuWxZw5c+If//hHHHroodG7d+948MEHo7S0NNf+iSeeWOtjvPDCC3HZZZfFcccdFw0aNFjj5y1btixq1Fi/X+tZtc2YMSOqVfO3WODHSWgCNgq//OUv85ZffPHFGDt2bIX137R06dKoU6fO+iyt4GrWrFnlx9xjjz3ylmvVqhXXX3997LHHHlV2Odu6qFGjRoX3zG9/+9u46qqr4qKLLoqTTjop7rvvvty24uLi9VpPeXl5rFixImrVqhW1atVar8f6LiUlJQU9PsD65E9CAP+/3r17x9Zbbx2TJk2KXXbZJerUqRMXX3xxREQ8+OCDsc8++0TLli2jpKQkOnbsGL/5zW+irKxstfuYPn167LbbblGnTp1o1apV/OEPf6hwvBtuuCG6du0aderUiYYNG0bPnj3j73//e277nDlz4rTTTostt9wyateuHY0bN47DDjssZs+eXWFfCxYsiLPPPjvat28fJSUl0bp16zj22GNj/vz58fTTT8f2228fERHHH3987vKyO+64IyJWf0/TkiVL4txzz402bdpESUlJbLnllvG///u/kVLKa1dUVBSDBg2KMWPGxNZbbx0lJSXRtWvXeOyxx9a2+/PcfvvtUVRUFK+++mqFbb/73e+ievXq8cEHH0RE/rjttNNOUbt27ejQoUPcfPPNFZ67fPnyGDJkSGy++eZRUlISbdq0ifPPPz+WL1/+veq98MILY88994yRI0fGzJkzc+tXd09T1rgPHTo0zjvvvIiI6NChQ26sVo35qv4ePnx4dO3aNUpKSnJ9/W2XM86fPz8OP/zwKC0tjcaNG8eZZ54ZX3zxRW777Nmz894PX/f1fX5Xbau7p+ndd9+Nww47LBo1ahR16tSJn/70p/HPf/4zr83TTz8dRUVFMWLEiLjiiiuidevWUatWrdh9993jnXfe+dY+B6hKzjQBfM0nn3wS/fr1iyOOOCJ++ctfRrNmzSIi4o477oi6devGOeecE3Xr1o2nnnoqBg8eHIsWLYqrr746bx+fffZZ7LXXXnHwwQfH4YcfHqNGjYoLLrggunXrFv369YuIlZfEnXHGGXHooYfm/hH7+uuvx0svvRRHHXVURKy8ZO2FF16II444Ilq3bh2zZ8+Om266KXr37h3Tp0/PnQH7/PPP4+c//3m8+eabccIJJ8RPfvKTmD9/fjz00EPxn//8Jzp37hyXX355DB48OE4++eT4+c9/HhERO+2002r7IKUU+++/f4wfPz5+9atfxTbbbBOPP/54nHfeefHBBx/Eddddl9f+ueeei/vvvz9OO+20qFevXlx//fVxyCGHxHvvvReNGzdep3E49NBDY+DAgTF8+PDYdttt87YNHz48evfuHa1atcrr87333jsOP/zwOPLII2PEiBHx61//OoqLi+OEE06IiJVnZfbff/947rnn4uSTT47OnTvH1KlT47rrrouZM2fGmDFj1qnWVY455ph44oknYuzYsbHFFlusts13jfvBBx8cM2fOjHvuuSeuu+66aNKkSURENG3aNLePp556KkaMGBGDBg2KJk2afOckHocffni0b98+rrzyynjxxRfj+uuvj88++yzuvPPOtXp9a1Lb13388cex0047xdKlS+OMM86Ixo0bx9/+9rfYf//9Y9SoUXHQQQfltb/qqquiWrVq8T//8z+xcOHC+MMf/hBHH310vPTSS2tVJ8B6kQA2QgMHDkzf/F/grrvumiIi3XzzzRXaL126tMK6U045JdWpUyd98cUXFfZx55135tYtX748NW/ePB1yyCG5dQcccEDq2rVrZo2rO+aECRMq7H/w4MEpItL9999foX15eXlKKaWJEyemiEi33357hTYDBgxI7dq1yy2PGTMmRUT67W9/m9fu0EMPTUVFRemdd97JrYuIVFxcnLfutddeSxGRbrjhhszX93UjR45MEZHGjx+fW3fkkUemli1bprKysty6yZMnV3gdq/r8mmuuya1bvnx52mabbdKmm26aVqxYkVJK6a677krVqlVL//rXv/KOffPNN6eISM8//3xmjQMGDEibbLLJt25/9dVXU0Sks88+O6+2XXfdNbe8JuN+9dVXp4hIs2bNqrAtIlK1atXSG2+8sdptQ4YMyS0PGTIkRUTaf//989qddtppKSLSa6+9llJKadasWd/63vjmPrNqa9euXRowYEBu+ayzzkoRkdffixcvTh06dEjt27fPjev48eNTRKTOnTun5cuX59r+6U9/ShGRpk6dWuFYAFXN5XkAX1NSUhLHH398hfW1a9fO/ffixYtj/vz58fOf/zyWLl0ab731Vl7bunXr5t33UlxcHDvssEO8++67uXUNGjSI//znPzFx4sRvreXrx/zyyy/jk08+ic033zwaNGgQkydPzm0bPXp09OjRo8Jf7iNWXl61th555JGoXr16nHHGGXnrzz333EgpxaOPPpq3vk+fPtGxY8fccvfu3aO0tDTv9a6LY489Nj788MMYP358bt3w4cOjdu3accghh+S1rVGjRpxyyim55eLi4jjllFNi3rx5MWnSpIiIGDlyZHTu3Dm22mqrmD9/fu7xi1/8IiIi7zjrom7duhGx8v3xbdZk3L/LrrvuGl26dFnj9gMHDsxbPv300yNi5TivT4888kjssMMO8bOf/Sy3rm7dunHyySfH7NmzY/r06Xntjz/++Lx7wFadEf2+7yOAyiA0AXxNq1atVnvz/htvvBEHHXRQ1K9fP0pLS6Np06a5YLRw4cK8tq1bt64QVho2bBifffZZbvmCCy6IunXrxg477BCdOnWKgQMHxvPPP5/3nGXLlsXgwYNz9xU1adIkmjZtGgsWLMg75r///e/Yeuutv/drX2XOnDnRsmXLqFevXt76VbPazZkzJ29927ZtK+zjm693Xeyxxx7RokWLGD58eESsvLzunnvuiQMOOKBCbS1btoxNNtkkb92qS+RW3XPz9ttvxxtvvBFNmzbNe6xqN2/evO9V7+effx4RUaG2r1uTcf8uHTp0WKv2nTp1ylvu2LFjVKtWbbX3xlWmOXPmxJZbbllh/Zq+jxo2bBgR8b3fRwCVwT1NAF/z9bM7qyxYsCB23XXXKC0tjcsvvzw6duwYtWrVismTJ8cFF1xQYbru6tWrr3bf6WuTKHTu3DlmzJgRDz/8cDz22GMxevTo+POf/xyDBw+Oyy67LCJWnhG4/fbb46yzzopevXpF/fr1o6ioKI444ogqnyI8y5q83nXd71FHHRW33npr/PnPf47nn38+Pvzww++c8fDblJeXR7du3eLaa69d7fY2bdp8n3Jj2rRpERGx+eabf2ubNRn377K69+ja+Gag/7azkd+c5GR9W1/vI4DKIDQBfIenn346Pvnkk7j//vtjl112ya2fNWvW99rvJptsEv3794/+/fvHihUr4uCDD44rrrgiLrrooqhVq1aMGjUqBgwYENdcc03uOV988UWFHxbt2LFj7h/s32ZtLtNr165dPPnkk7F48eK8syarLkNs167dGu/r+zr22GPjmmuuiX/84x/x6KOPRtOmTaNv374V2n344YexZMmSvLNNq2axWzVRQseOHeO1116L3XfffZ0uW/wud911VxQVFVWYTv2bvmvcK7u2t99+O+/s1DvvvBPl5eW5fll1Rueb76tvngmKWPv30YwZMyqsL8T7COD7cnkewHdY9Rfwr//Fe8WKFfHnP/95nff5ySef5C0XFxdHly5dIqUUX375Ze643/wr+w033FDhDMAhhxwSr732WjzwwAMVjrPq+avCxDf/Ybw6e++9d5SVlcWNN96Yt/66666LoqKi3AyAVaF79+7RvXv3uO2222L06NFxxBFHrPYHXL/66qv4y1/+kltesWJF/OUvf4mmTZvGdtttFxErZ5H74IMP4tZbb63w/GXLlsWSJUvWuc6rrroqnnjiiejfv3+Fy+G+bk3GfW3Gak0MGzYsb/mGG26IiMiNY2lpaTRp0iSeffbZvHare3+v7fvo5ZdfjgkTJuTWLVmyJG655ZZo3779Wt2XBVBozjQBfIeddtopGjZsGAMGDIgzzjgjioqK4q677vpelw3tueee0bx589h5552jWbNm8eabb8aNN94Y++yzT+7szr777ht33XVX1K9fP7p06RITJkyIJ598ssI03uedd16MGjUqDjvssDjhhBNiu+22i08//TQeeuihuPnmm6NHjx7RsWPHaNCgQdx8881Rr1692GSTTWLHHXdc7f0x++23X+y2225xySWXxOzZs6NHjx7xxBNPxIMPPhhnnXVW3qQPVeHYY4+N//mf/4mIij9SvErLli3j97//fcyePTu22GKLuO+++2LKlClxyy235H6895hjjokRI0bEqaeeGuPHj4+dd945ysrK4q233ooRI0bE448/Hj179sys5auvvoq77747Ilae9ZszZ0489NBD8frrr8duu+0Wt9xyS+bz12TcV4W8Sy65JI444oioWbNm7LfffhXu2VpTs2bNiv333z/22muvmDBhQtx9991x1FFHRY8ePXJtTjzxxLjqqqvixBNPjJ49e8azzz6b93tTq6xNbRdeeGHcc8890a9fvzjjjDOiUaNG8be//S1mzZoVo0ePjmrV/N0W2IAUato+gEL6tinHv2066Oeffz799Kc/TbVr104tW7ZM559/fnr88ccrTJP9bfv45rTef/nLX9Iuu+ySGjdunEpKSlLHjh3TeeedlxYuXJhr89lnn6Xjjz8+NWnSJNWtWzf17ds3vfXWWxWmdk4ppU8++SQNGjQotWrVKhUXF6fWrVunAQMGpPnz5+faPPjgg6lLly6pRo0aeVNMf7O2lFZODX322Wenli1bppo1a6ZOnTqlq6++OjeF+SoRkQYOHFjh9a6uxiyrm3J8lY8++ihVr149bbHFFqt97qo+f+WVV1KvXr1SrVq1Urt27dKNN95Yoe2KFSvS73//+9S1a9dUUlKSGjZsmLbbbrt02WWX5fX96gwYMCBFRO5Rp06d1L59+3TIIYekUaNG5U2N/vXavj7l+JqMe0op/eY3v0mtWrVK1apVy5vi+9v6e9W21U05Pn369HTooYemevXqpYYNG6ZBgwalZcuW5T136dKl6Ve/+lWqX79+qlevXjr88MPTvHnzKuwzq7bVjfm///3vdOihh6YGDRqkWrVqpR122CE9/PDDeW1WTTk+cuTIvPVZU6EDVLWilNxhCcAP1/z586NFixYxePDguPTSSyts7927d8yfP/877+sCgHXl3DgAP2h33HFHlJWVxTHHHFPoUgDYSLmnCYAfpKeeeiqmT58eV1xxRRx44IG52d4AoKoJTQD8IF1++eXxwgsvxM4775yb8Q0ACsE9TQAAABnc0wQAAJBBaAIAAMiwQd/TVF5eHh9++GHUq1cvioqKCl0OAABQICmlWLx4cbRs2bLSf0B7gw5NH374YbRp06bQZQAAAD8Q77//frRu3bpS97lBh6Z69epFxMqOKS0tLXA1AABAoSxatCjatGmTywiVaYMOTasuySstLRWaAACA9XLbjokgAAAAMghNAAAAGYQmAACADEITAABABqEJAAAgg9AEAACQQWgCAADIIDQBAABkEJoAAAAyCE0AAAAZhCYAAIAMQhMAAEAGoQkAACCD0AQAAJBBaAIAAMggNAEAAGQQmgAAADIITQAAABmEJgAAgAxCEwAAQAahCQAAIIPQBAAAkEFoAgAAyCA0AQAAZBCaAAAAMghNAAAAGYQmAACADEITAABABqEJAAAgg9AEAACQQWgCAADIIDQBAABkEJoAAAAyCE0AAAAZhCYAAIAMQhMAAEAGoQkAACCD0AQAAJBBaAIAAMggNAEAAGQQmgAAADIITQAAABmEJgAAgAxCEwAAQAahCQAAIEONQhdQGR56e27UqbvkW7cfvGWLKqwGAAD4MXGmCQAAIIPQBAAAkEFoAgAAyCA0AQAAZBCaAAAAMghNAAAAGYQmAACADEITAABABqEJAAAgg9AEAACQQWgCAADIIDQBAABkEJoAAAAyCE0AAAAZhCYAAIAMQhMAAEAGoQkAACCD0AQAAJBBaAIAAMggNAEAAGQQmgAAADIITQAAABmEJgAAgAxCEwAAQAahCQAAIIPQBAAAkEFoAgAAyCA0AQAAZBCaAAAAMghNAAAAGYQmAACADEITAABABqEJAAAgg9AEAACQQWgCAADIIDQBAABkEJoAAAAyCE0AAAAZhCYAAIAMQhMAAEAGoQkAACCD0AQAAJBBaAIAAMhQ0ND07LPPxn777RctW7aMoqKiGDNmTCHLAQAAqKCgoWnJkiXRo0ePGDZsWCHLAAAA+FY1Cnnwfv36Rb9+/QpZAgAAQKaChqa1tXz58li+fHluedGiRQWsBgAA2BhsUBNBXHnllVG/fv3co02bNoUuCQAA+JHboELTRRddFAsXLsw93n///UKXBAAA/MhtUJfnlZSURElJSaHLAAAANiIb1JkmAACAqlbQM02ff/55vPPOO7nlWbNmxZQpU6JRo0bRtm3bAlYGAACwUkFD0yuvvBK77bZbbvmcc86JiIgBAwbEHXfcUaCqAAAA/p+ChqbevXtHSqmQJQAAAGRyTxMAAEAGoQkAACCD0AQAAJBBaAIAAMggNAEAAGQQmgAAADIITQAAABmEJgAAgAxCEwAAQAahCQAAIIPQBAAAkEFoAgAAyCA0AQAAZBCaAAAAMghNAAAAGYQmAACADEITAABABqEJAAAgg9AEAACQQWgCAADIIDQBAABkEJoAAAAyCE0AAAAZhCYAAIAMQhMAAEAGoQkAACCD0AQAAJBBaAIAAMggNAEAAGQQmgAAADIITQAAABmEJgAAgAxCEwAAQAahCQAAIIPQBAAAkEFoAgAAyCA0AQAAZBCaAAAAMghNAAAAGYQmAACADEITAABAhhqFLqAy7N+peZSWlha6DAAA4EfImSYAAIAMQhMAAEAGoQkAACCD0AQAAJBBaAIAAMggNAEAAGQQmgAAADIITQAAABmEJgAAgAxCEwAAQAahCQAAIIPQBAAAkEFoAgAAyCA0AQAAZBCaAAAAMghNAAAAGYQmAACADEITAABABqEJAAAgg9AEAACQQWgCAADIIDQBAABkEJoAAAAyCE0AAAAZhCYAAIAMQhMAAEAGoQkAACCD0AQAAJBBaAIAAMggNAEAAGQQmgAAADIITQAAABnWKTQ99thj8dxzz+WWhw0bFttss00cddRR8dlnn1VacQAAAIW2TqHpvPPOi0WLFkVExNSpU+Pcc8+NvffeO2bNmhXnnHNOpRYIAABQSDXW5UmzZs2KLl26RETE6NGjY999943f/e53MXny5Nh7770rtUAAAIBCWqczTcXFxbF06dKIiHjyySdjzz33jIiIRo0a5c5AAQAA/Bis05mmn/3sZ3HOOefEzjvvHC+//HLcd999ERExc+bMaN26daUWCAAAUEjrdKbpxhtvjBo1asSoUaPipptuilatWkVExKOPPhp77bVXpRYIAABQSEUppVToItbVokWLon79+rFw4cIoLS0tdDkAAECBrM9ssE5nmiZPnhxTp07NLT/44INx4IEHxsUXXxwrVqyotOIAAAAKbZ1C0ymnnBIzZ86MiIh33303jjjiiKhTp06MHDkyzj///EotEAAAoJDWKTTNnDkzttlmm4iIGDlyZOyyyy7x97//Pe64444YPXp0ZdYHAABQUOsUmlJKUV5eHhErpxxf9dtMbdq0ifnz51dedQAAAAW2TqGpZ8+e8dvf/jbuuuuueOaZZ2KfffaJiJU/etusWbNKLRAAAKCQ1ik0/fGPf4zJkyfHoEGD4pJLLonNN988IiJGjRoVO+20U6UWCAAAUEiVOuX4F198EdWrV4+aNWtW1i4zmXIcAACIWL/ZoEZl7qxWrVqVuTsAAICCW6fQVFZWFtddd12MGDEi3nvvvQq/zfTpp59WSnEAAACFtk73NF122WVx7bXXRv/+/WPhwoVxzjnnxMEHHxzVqlWLoUOHVnKJAAAAhbNOoWn48OFx6623xrnnnhs1atSII488Mm677bYYPHhwvPjii5VdIwAAQMGsU2iaO3dudOvWLSIi6tatGwsXLoyIiH333Tf++c9/Vl51AAAABbZOoal169bx0UcfRUREx44d44knnoiIiIkTJ0ZJSUnlVQcAAFBg6xSaDjrooBg3blxERJx++ulx6aWXRqdOneLYY4+NE044oVILBAAAKKRK+Z2mCRMmxIQJE6JTp06x3377VUZda8TvNAEAABEbwO809erVK3r16lUZuwIAAPhBWePQ9NBDD63xTvfff/91KgYAAOCHZo1D04EHHrhG7YqKiqKsrGxd6wEAAPhBWePQVF5evj7rAAAA+EFaq9nznnrqqejSpUssWrSowraFCxdG165d41//+lelFQcAAFBoaxWa/vjHP8ZJJ5202tko6tevH6ecckpce+21lVYcAABAoa1VaHrttddir732+tbte+65Z0yaNOl7FwUAAPBDsVah6eOPP46aNWt+6/YaNWrEf//73+9dFAAAwA/FWoWmVq1axbRp0751++uvvx4tWrT43kUBAAD8UKxVaNp7773j0ksvjS+++KLCtmXLlsWQIUNi3333rbTiAAAACq0opZTWtPHHH38cP/nJT6J69eoxaNCg2HLLLSMi4q233ophw4ZFWVlZTJ48OZo1a7beCv66RYsWRf369WPhwoWrnZwCAADYOKzPbLDGv9MUEdGsWbN44YUX4te//nVcdNFFsSpvFRUVRd++fWPYsGFVFpgAAACqwlqFpoiIdu3axSOPPBKfffZZvPPOO5FSik6dOkXDhg3XR30AAAAFtdahaZWGDRvG9ttvX5m1AAAA/OCs1UQQAAAAGxuhCQAAIIPQBAAAkEFoAgAAyCA0AQAAZBCaAAAAMghNAAAAGYQmAACADEITAABABqEJAAAgg9AEAACQQWgCAADIIDQBAABkEJoAAAAyCE0AAAAZhCYAAIAMQhMAAEAGoQkAACCD0AQAAJBBaAIAAMggNAEAAGQQmgAAADIITQAAABmEJgAAgAxCEwAAQAahCQAAIIPQBAAAkKFGoQuoDA+9PTfq1F1S6DIAAGCjcfCWLQpdQpVxpgkAACCD0AQAAJBBaAIAAMggNAEAAGQQmgAAADIITQAAABmEJgAAgAxCEwAAQAahCQAAIIPQBAAAkEFoAgAAyCA0AQAAZBCaAAAAMghNAAAAGYQmAACADEITAABABqEJAAAgg9AEAACQQWgCAADIIDQBAABkEJoAAAAyCE0AAAAZhCYAAIAMQhMAAEAGoQkAACCD0AQAAJBBaAIAAMggNAEAAGQQmgAAADIITQAAABmEJgAAgAxCEwAAQAahCQAAIIPQBAAAkEFoAgAAyCA0AQAAZBCaAAAAMghNAAAAGYQmAACADEITAABABqEJAAAgg9AEAACQQWgCAADIIDQBAABk+EGEpmHDhkX79u2jVq1aseOOO8bLL79c6JIAAAAi4gcQmu67774455xzYsiQITF58uTo0aNH9O3bN+bNm1fo0gAAAAofmq699to46aST4vjjj48uXbrEzTffHHXq1Im//vWvFdouX748Fi1alPcAAABYnwoamlasWBGTJk2KPn365NZVq1Yt+vTpExMmTKjQ/sorr4z69evnHm3atKnKcgEAgI1QQUPT/Pnzo6ysLJo1a5a3vlmzZjF37twK7S+66KJYuHBh7vH+++9XVakAAMBGqkahC1gbJSUlUVJSUugyAACAjUhBzzQ1adIkqlevHh9//HHe+o8//jiaN29eoKoAAAD+n4KGpuLi4thuu+1i3LhxuXXl5eUxbty46NWrVwErAwAAWKngl+edc845MWDAgOjZs2fssMMO8cc//jGWLFkSxx9/fKFLAwAAKHxo6t+/f/z3v/+NwYMHx9y5c2ObbbaJxx57rMLkEAAAAIVQlFJKhS5iXS1atCjq168fd70yI+rUrVfocgAAYKNx8JYtCl1CnlXZYOHChVFaWlqp+y74j9sCAAD8kAlNAAAAGYQmAACADEITAABABqEJAAAgg9AEAACQQWgCAADIIDQBAABkEJoAAAAyCE0AAAAZhCYAAIAMQhMAAEAGoQkAACCD0AQAAJBBaAIAAMggNAEAAGQQmgAAADIITQAAABmEJgAAgAxCEwAAQAahCQAAIIPQBAAAkEFoAgAAyCA0AQAAZBCaAAAAMghNAAAAGYQmAACADEITAABABqEJAAAgg9AEAACQQWgCAADIIDQBAABkEJoAAAAyCE0AAAAZhCYAAIAMQhMAAEAGoQkAACCD0AQAAJBBaAIAAMggNAEAAGQQmgAAADLUKHQBlWH/Ts2jtLS00GUAAAA/Qs40AQAAZBCaAAAAMghNAAAAGYQmAACADEITAABABqEJAAAgg9AEAACQQWgCAADIIDQBAABkEJoAAAAyCE0AAAAZhCYAAIAMQhMAAEAGoQkAACCD0AQAAJBBaAIAAMggNAEAAGQQmgAAADIITQAAABmEJgAAgAxCEwAAQAahCQAAIIPQBAAAkEFoAgAAyCA0AQAAZBCaAAAAMghNAAAAGYQmAACADEITAABABqEJAAAgg9AEAACQQWgCAADIIDQBAABkEJoAAAAyCE0AAAAZhCYAAIAMQhMAAEAGoQkAACCD0AQAAJBBaAIAAMggNAEAAGQQmgAAADIITQAAABmEJgAAgAxCEwAAQAahCQAAIEONQhfwfaSUIiJi0aJFBa4EAAAopFWZYFVGqEwbdGj65JNPIiKiTZs2Ba4EAAD4IVi8eHHUr1+/Uve5QYemRo0aRUTEe++9V+kdw5pZtGhRtGnTJt5///0oLS0tdDkbJWNQWPq/8IxB4RmDwjMGhaX/C2/VGEyfPj1atmxZ6fvfoENTtWorb8mqX7++N2iBlZaWGoMCMwaFpf8LzxgUnjEoPGNQWPq/8Fq1apXLCJXJRBAAAAAZhCYAAIAMG3RoKikpiSFDhkRJSUmhS9loGYPCMwaFpf8LzxgUnjEoPGNQWPq/8Nb3GBSl9TEnHwAAwI/EBn2mCQAAYH0TmgAAADIITQAAABmEJgAAgAwbdGgaNmxYtG/fPmrVqhU77rhjvPzyy4Uu6Ufh2Wefjf322y9atmwZRUVFMWbMmLztKaUYPHhwtGjRImrXrh19+vSJt99+O6/Np59+GkcffXSUlpZGgwYN4le/+lV8/vnnVfgqNlxXXnllbL/99lGvXr3YdNNN48ADD4wZM2bktfniiy9i4MCB0bhx46hbt24ccsgh8fHHH+e1ee+992KfffaJOnXqxKabbhrnnXdefPXVV1X5UjZYN910U3Tv3j33I4W9evWKRx99NLdd/1e9q666KoqKiuKss87KrTMO69fQoUOjqKgo77HVVlvltuv/9e+DDz6IX/7yl9G4ceOoXbt2dOvWLV555ZXcdt/H61f79u0rfAaKiopi4MCBEeEzUBXKysri0ksvjQ4dOkTt2rWjY8eO8Zvf/Ca+Po9dlX0O0gbq3nvvTcXFxemvf/1reuONN9JJJ52UGjRokD7++ONCl7bBe+SRR9Ill1yS7r///hQR6YEHHsjbftVVV6X69eunMWPGpNdeey3tv//+qUOHDmnZsmW5NnvttVfq0aNHevHFF9O//vWvtPnmm6cjjzyyil/Jhqlv377p9ttvT9OmTUtTpkxJe++9d2rbtm36/PPPc21OPfXU1KZNmzRu3Lj0yiuvpJ/+9Kdpp512ym3/6quv0tZbb5369OmTXn311fTII4+kJk2apIsuuqgQL2mD89BDD6V//vOfaebMmWnGjBnp4osvTjVr1kzTpk1LKen/qvbyyy+n9u3bp+7du6czzzwzt944rF9DhgxJXbt2TR999FHu8d///je3Xf+vX59++mlq165dOu6449JLL72U3n333fT444+nd955J9fG9/H6NW/evLz3/9ixY1NEpPHjx6eUfAaqwhVXXJEaN26cHn744TRr1qw0cuTIVLdu3fSnP/0p16aqPgcbbGjaYYcd0sCBA3PLZWVlqWXLlunKK68sYFU/Pt8MTeXl5al58+bp6quvzq1bsGBBKikpSffcc09KKaXp06eniEgTJ07MtXn00UdTUVFR+uCDD6qs9h+LefPmpYhIzzzzTEppZX/XrFkzjRw5MtfmzTffTBGRJkyYkFJaGXyrVauW5s6dm2tz0003pdLS0rR8+fKqfQE/Eg0bNky33Xab/q9iixcvTp06dUpjx45Nu+66ay40GYf1b8iQIalHjx6r3ab/178LLrgg/exnP/vW7b6Pq96ZZ56ZOnbsmMrLy30Gqsg+++yTTjjhhLx1Bx98cDr66KNTSlX7OdggL89bsWJFTJo0Kfr06ZNbV61atejTp09MmDChgJX9+M2aNSvmzp2b1/f169ePHXfcMdf3EyZMiAYNGkTPnj1zbfr06RPVqlWLl156qcpr3tAtXLgwIiIaNWoUERGTJk2KL7/8Mm8Mttpqq2jbtm3eGHTr1i2aNWuWa9O3b99YtGhRvPHGG1VY/YavrKws7r333liyZEn06tVL/1exgQMHxj777JPX3xE+B1Xl7bffjpYtW8Zmm20WRx99dLz33nsRof+rwkMPPRQ9e/aMww47LDbddNPYdttt49Zbb81t931ctVasWBF33313nHDCCVFUVOQzUEV22mmnGDduXMycOTMiIl577bV47rnnol+/fhFRtZ+DGpXxgqra/Pnzo6ysLO9NGBHRrFmzeOuttwpU1cZh7ty5ERGr7ftV2+bOnRubbrpp3vYaNWpEo0aNcm1YM+Xl5XHWWWfFzjvvHFtvvXVErOzf4uLiaNCgQV7bb47B6sZo1Ta+29SpU6NXr17xxRdfRN26deOBBx6ILl26xJQpU/R/Fbn33ntj8uTJMXHixArbfA7Wvx133DHuuOOO2HLLLeOjjz6Kyy67LH7+85/HtGnT9H8VePfdd+Omm26Kc845Jy6++OKYOHFinHHGGVFcXBwDBgzwfVzFxowZEwsWLIjjjjsuIvw/qKpceOGFsWjRothqq62ievXqUVZWFldccUUcffTREVG1/y7dIEMTbCwGDhwY06ZNi+eee67QpWx0ttxyy5gyZUosXLgwRo0aFQMGDIhnnnmm0GVtNN5///0488wzY+zYsVGrVq1Cl7NRWvWX3IiI7t27x4477hjt2rWLESNGRO3atQtY2cahvLw8evbsGb/73e8iImLbbbeNadOmxc033xwDBgwocHUbn//7v/+Lfv36RcuWLQtdykZlxIgRMXz48Pj73/8eXbt2jSlTpsRZZ50VLVu2rPLPwQZ5eV6TJk2ievXqFWYo+fjjj6N58+YFqmrjsKp/s/q+efPmMW/evLztX331VXz66afGZy0MGjQoHn744Rg/fny0bt06t7558+axYsWKWLBgQV77b47B6sZo1Ta+W3FxcWy++eax3XbbxZVXXhk9evSIP/3pT/q/ikyaNCnmzZsXP/nJT6JGjRpRo0aNeOaZZ+L666+PGjVqRLNmzYxDFWvQoEFsscUW8c477/gcVIEWLVpEly5d8tZ17tw5d4mk7+OqM2fOnHjyySfjxBNPzK3zGaga5513Xlx44YVxxBFHRLdu3eKYY46Js88+O6688sqIqNrPwQYZmoqLi2O77baLcePG5daVl5fHuHHjolevXgWs7MevQ4cO0bx587y+X7RoUbz00ku5vu/Vq1csWLAgJk2alGvz1FNPRXl5eey4445VXvOGJqUUgwYNigceeCCeeuqp6NChQ9727bbbLmrWrJk3BjNmzIj33nsvbwymTp2a9z+JsWPHRmlpaYUvYdZMeXl5LF++XP9Xkd133z2mTp0aU6ZMyT169uwZRx99dO6/jUPV+vzzz+Pf//53tGjRwuegCuy8884Vfm5i5syZ0a5du4jwfVyVbr/99th0001jn332ya3zGagaS5cujWrV8uNK9erVo7y8PCKq+HPwPSa0KKh77703lZSUpDvuuCNNnz49nXzyyalBgwZ5M5SwbhYvXpxeffXV9Oqrr6aISNdee2169dVX05w5c1JKK6d2bNCgQXrwwQfT66+/ng444IDVTu247bbbppdeeik999xzqVOnTqY4XUO//vWvU/369dPTTz+dN9Xp0qVLc21OPfXU1LZt2/TUU0+lV155JfXq1Sv16tUrt33VNKd77rlnmjJlSnrsscdS06ZNTXO6hi688ML0zDPPpFmzZqXXX389XXjhhamoqCg98cQTKSX9Xyhfnz0vJeOwvp177rnp6aefTrNmzUrPP/986tOnT2rSpEmaN29eSkn/r28vv/xyqlGjRrriiivS22+/nYYPH57q1KmT7r777lwb38frX1lZWWrbtm264IILKmzzGVj/BgwYkFq1apWbcvz+++9PTZo0Seeff36uTVV9DjbY0JRSSjfccENq27ZtKi4uTjvssEN68cUXC13Sj8L48eNTRFR4DBgwIKW0cnrHSy+9NDVr1iyVlJSk3XffPc2YMSNvH5988kk68sgjU926dVNpaWk6/vjj0+LFiwvwajY8q+v7iEi33357rs2yZcvSaaedlho2bJjq1KmTDjrooPTRRx/l7Wf27NmpX79+qXbt2qlJkybp3HPPTV9++WUVv5oN0wknnJDatWuXiouLU9OmTdPuu++eC0wp6f9C+WZoMg7rV//+/VOLFi1ScXFxatWqVerfv3/ebwTp//XvH//4R9p6661TSUlJ2mqrrdItt9ySt9338fr3+OOPp4io0K8p+QxUhUWLFqUzzzwztW3bNtWqVSttttlm6ZJLLsmbsr2qPgdFKX3tJ3UBAADIs0He0wQAAFBVhCYAAIAMQhMAAEAGoQkAACCD0AQAAJBBaAIAAMggNAEAAGQQmgAAADIITQAAABmEJgAKau7cuXH66afHZpttFiUlJdGmTZvYb7/9Yty4cVVaR1FRUYwZM6ZKjwnAhqFGoQsAYOM1e/bs2HnnnaNBgwZx9dVXR7du3eLLL7+Mxx9/PAYOHBhvvfVWoUsEgChKKaVCFwHAxmnvvfeO119/PWbMmBGbbLJJ3rYFCxZEgwYN4r333ovTTz89xo0bF9WqVYu99torbrjhhmjWrFlERBx33HGxYMGCvLNEZ511VkyZMiWefvrpiIjo3bt3dO/ePWrVqhW33XZbFBcXx6mnnhpDhw6NiIj27dvHnDlzcs9v165dzJ49e32+dAA2IC7PA6AgPv3003jsscdi4MCBFQJTRESDBg2ivLw8DjjggPj000/jmWeeibFjx8a7774b/fv3X+vj/e1vf4tNNtkkXnrppfjDH/4Ql19+eYwdOzYiIiZOnBgREbfffnt89NFHuWUAiHB5HgAF8s4770RKKbbaaqtvbTNu3LiYOnVqzJo1K9q0aRMREXfeeWd07do1Jk6cGNtvv/0aH6979+4xZMiQiIjo1KlT3HjjjTFu3LjYY489omnTphGxMqg1b978e7wqAH6MnGkCoCDW5OrwN998M9q0aZMLTBERXbp0iQYNGsSbb765Vsfr3r173nKLFi1i3rx5a7UPADZOQhMABdGpU6coKir63pM9VKtWrUIA+/LLLyu0q1mzZt5yUVFRlJeXf69jA7BxEJoAKIhGjRpF3759Y9iwYbFkyZIK2xcsWBCdO3eO999/P95///3c+unTp8eCBQuiS5cuERHRtGnT+Oijj/KeO2XKlLWup2bNmlFWVrbWzwPgx09oAqBghg0bFmVlZbHDDjvE6NGj4+23344333wzrr/++ujVq1f06dMnunXrFkcffXRMnjw5Xn755Tj22GNj1113jZ49e0ZExC9+8Yt45ZVX4s4774y33347hgwZEtOmTVvrWtq3bx/jxo2LuXPnxmeffVbZLxWADZjQBEDBbLbZZjF58uTYbbfd4txzz42tt9469thjjxg3blzcdNNNUVRUFA8++GA0bNgwdtlll+jTp09sttlmcd999+X20bdv37j00kvj/PPPj+233z4WL14cxx577FrXcs0118TYsWOjTZs2se2221bmywRgA+d3mgAAADI40wQAAJBBaAIAAMggNAEAAGQQmgAAADIITQAAABmEJgAAgAxCEwAAQAahCQAAIIPQBAAAkEFoAgAAyCA0AQAAZPj/AHGUn/xJilZDAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "fraud_distribution.plot(kind='barh', color='lightblue', \n",
    "                       title=\"Transaction Type Distribution\")\n",
    "plt.xlabel(\"Count\")\n",
    "plt.ylabel(\"Class\") #Visualizes the distribution of transaction types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "target = transaction_data['Class']\n",
    "features = transaction_data.drop(['Class'], axis=1)\n",
    "\n",
    "smote_balancer = SMOTE(random_state=42)\n",
    "features_balanced, target_balanced = smote_balancer.fit_resample(features, target) #Applies SMOTE to balance the dataset by oversampling the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced dataset shape: (1526, 31)\n",
      "Class distribution:\n",
      " Class\n",
      "0    763\n",
      "1    763\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "processed_data = pd.concat([\n",
    "    pd.DataFrame(features_balanced),\n",
    "    pd.DataFrame(target_balanced, columns=['Class'])\n",
    "], axis=1)\n",
    "\n",
    "print(\"Balanced dataset shape:\", processed_data.shape)\n",
    "print(\"Class distribution:\\n\", processed_data['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1 = processed_data.sample(n=int(0.2 * len(processed_data)), random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adrij\\AppData\\Local\\Temp\\ipykernel_19328\\2438196681.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sample2 = grouped.apply(lambda x: x.sample(int(0.2 * len(x)), random_state=42)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "grouped = processed_data.groupby('Class')\n",
    "sample2 = grouped.apply(lambda x: x.sample(int(0.2 * len(x)), random_state=42)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = len(processed_data) // int(0.2 * len(processed_data))\n",
    "offset = np.random.randint(0, interval)\n",
    "sample3 = processed_data.iloc[offset::interval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_groups = 5\n",
    "group_ids = np.arange(len(processed_data)) % n_groups\n",
    "processed_data['Group'] = group_ids\n",
    "selected_group = np.random.randint(0, n_groups)\n",
    "sample4 = processed_data[processed_data['Group'] == selected_group].drop('Group', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sizes: 305 304 306 305 305\n"
     ]
    }
   ],
   "source": [
    "sample5 = processed_data.sample(n=int(0.2 * len(processed_data)), replace=True, random_state=42)\n",
    "\n",
    "print(\"Sample sizes:\", len(sample1), len(sample2), len(sample3), len(sample4), len(sample5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42),\n",
    "    \"SVM\": SVC(),\n",
    "    \"k-NN\": KNeighborsClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_metrics = {}\n",
    "sample_set = [sample1, sample2, sample3, sample4, sample5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adrij\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adrij\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adrij\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adrij\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adrij\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Logistic Regression  Decision Tree  Gradient Boosting       SVM  \\\n",
      "Sample1             0.918033       0.901639           0.934426  0.721311   \n",
      "Sample2             0.950820       0.901639           0.934426  0.754098   \n",
      "Sample3             0.741935       0.903226           0.951613  0.677419   \n",
      "Sample4             0.983607       0.950820           0.950820  0.688525   \n",
      "Sample5             0.950820       0.967213           0.967213  0.639344   \n",
      "\n",
      "             k-NN  \n",
      "Sample1  0.655738  \n",
      "Sample2  0.754098  \n",
      "Sample3  0.725806  \n",
      "Sample4  0.754098  \n",
      "Sample5  0.754098  \n"
     ]
    }
   ],
   "source": [
    "for model_name, classifier in classifiers.items():\n",
    "    performance_metrics[model_name] = []\n",
    "    \n",
    "    for i, sample in enumerate(sample_set):\n",
    "        X = sample.drop('Class', axis=1)\n",
    "        y = sample['Class']\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        classifier.fit(X_train, y_train)\n",
    "        predictions = classifier.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        performance_metrics[model_name].append(accuracy)\n",
    "\n",
    "results_table = pd.DataFrame(performance_metrics, index=[\"Sample1\", \"Sample2\", \"Sample3\", \"Sample4\", \"Sample5\"])\n",
    "print(results_table)\n",
    "results_table.to_csv(\"model_accuracy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_table.to_csv('Submission_102203509_ADRIJA.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
